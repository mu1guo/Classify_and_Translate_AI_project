{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T05:27:24.351652Z",
     "iopub.status.busy": "2022-07-20T05:27:24.350929Z",
     "iopub.status.idle": "2022-07-20T05:27:26.428062Z",
     "shell.execute_reply": "2022-07-20T05:27:26.426855Z",
     "shell.execute_reply.started": "2022-07-20T05:27:24.351608Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/paddle/lib/python3.8/site-packages/setuptools/sandbox.py:13: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "/root/miniconda3/envs/paddle/lib/python3.8/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/root/miniconda3/envs/paddle/lib/python3.8/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n"
     ]
    }
   ],
   "source": [
    "# 数据科学包\n",
    "import numpy as np                 # 常用数据科学包\n",
    "import pandas as pd                # 文本读取\n",
    "\n",
    "# 深度学习包\n",
    "import paddle\n",
    "from paddle.io import Dataset, DataLoader  # 定义数据集\n",
    "import paddle.nn as nn                     # 网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、准备数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用pandas读取数据集\n",
    "train_data = pd.read_table('./data/train.txt', sep='\\t',header=None)  # 训练集\n",
    "dev_data = pd.read_table('./data/dev.txt', sep='\\t',header=None)      # 验证集\n",
    "test_data = pd.read_table('./data/test.txt', sep='\\t',header=None)    # 测试集\n",
    "\n",
    "# 由于数据集存放时无列名，因此手动添加列名便于对数据进行更好处理\n",
    "train_data.columns = [\"text\",'label']\n",
    "dev_data.columns = [\"text\",'label']\n",
    "test_data.columns = [\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>网易第三季度业绩低于分析师预期</td>\n",
       "      <td>科技</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>巴萨1年前地狱重现这次却是天堂 再赴魔鬼客场必翻盘</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>美国称支持向朝鲜提供紧急人道主义援助</td>\n",
       "      <td>时政</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>增资交银康联 交行夺参股险商首单</td>\n",
       "      <td>股票</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>午盘：原材料板块领涨大盘</td>\n",
       "      <td>股票</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752466</th>\n",
       "      <td>天津女排奇迹之源竟在场边 他是五冠王真正核心</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752467</th>\n",
       "      <td>北电网络专利拍卖推迟：可能分拆6部分拍卖</td>\n",
       "      <td>科技</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752468</th>\n",
       "      <td>Spirit AeroSystems债券发行价确定</td>\n",
       "      <td>股票</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752469</th>\n",
       "      <td>陆慧明必发火线：法兰克福无胜 曼联国米顺利过关</td>\n",
       "      <td>彩票</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752470</th>\n",
       "      <td>首破万元 索尼46寸全新LED液晶特价促</td>\n",
       "      <td>科技</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752471 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text label\n",
       "0                 网易第三季度业绩低于分析师预期    科技\n",
       "1       巴萨1年前地狱重现这次却是天堂 再赴魔鬼客场必翻盘    体育\n",
       "2              美国称支持向朝鲜提供紧急人道主义援助    时政\n",
       "3                增资交银康联 交行夺参股险商首单    股票\n",
       "4                    午盘：原材料板块领涨大盘    股票\n",
       "...                           ...   ...\n",
       "752466     天津女排奇迹之源竟在场边 他是五冠王真正核心    体育\n",
       "752467       北电网络专利拍卖推迟：可能分拆6部分拍卖    科技\n",
       "752468  Spirit AeroSystems债券发行价确定    股票\n",
       "752469    陆慧明必发火线：法兰克福无胜 曼联国米顺利过关    彩票\n",
       "752470       首破万元 索尼46寸全新LED液晶特价促    科技\n",
       "\n",
       "[752471 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'科技': 0, '体育': 1, '时政': 2, '股票': 3, '娱乐': 4, '教育': 5, '家居': 6, '财经': 7, '房产': 8, '社会': 9, '游戏': 10, '彩票': 11, '星座': 12, '时尚': 13}\n"
     ]
    }
   ],
   "source": [
    "# 定义要进行分类的类别\n",
    "label_list=list(train_data.label.unique())\n",
    "label_word2num = { \n",
    "    label_text : idx for idx, label_text in enumerate(label_list)\n",
    "}\n",
    "label_num2word = { \n",
    "    idx : label_text for idx, label_text in enumerate(label_list)\n",
    "}\n",
    "print(label_word2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>网易第三季度业绩低于分析师预期</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>巴萨1年前地狱重现这次却是天堂 再赴魔鬼客场必翻盘</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>美国称支持向朝鲜提供紧急人道主义援助</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>增资交银康联 交行夺参股险商首单</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>午盘：原材料板块领涨大盘</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752466</th>\n",
       "      <td>天津女排奇迹之源竟在场边 他是五冠王真正核心</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752467</th>\n",
       "      <td>北电网络专利拍卖推迟：可能分拆6部分拍卖</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752468</th>\n",
       "      <td>Spirit AeroSystems债券发行价确定</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752469</th>\n",
       "      <td>陆慧明必发火线：法兰克福无胜 曼联国米顺利过关</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752470</th>\n",
       "      <td>首破万元 索尼46寸全新LED液晶特价促</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752471 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text label\n",
       "0                 网易第三季度业绩低于分析师预期     0\n",
       "1       巴萨1年前地狱重现这次却是天堂 再赴魔鬼客场必翻盘     1\n",
       "2              美国称支持向朝鲜提供紧急人道主义援助     2\n",
       "3                增资交银康联 交行夺参股险商首单     3\n",
       "4                    午盘：原材料板块领涨大盘     3\n",
       "...                           ...   ...\n",
       "752466     天津女排奇迹之源竟在场边 他是五冠王真正核心     1\n",
       "752467       北电网络专利拍卖推迟：可能分拆6部分拍卖     0\n",
       "752468  Spirit AeroSystems债券发行价确定     3\n",
       "752469    陆慧明必发火线：法兰克福无胜 曼联国米顺利过关    11\n",
       "752470       首破万元 索尼46寸全新LED液晶特价促     0\n",
       "\n",
       "[752471 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标签：文本转数字\n",
    "train_data.iloc[:, 1] = train_data.iloc[:, 1].map(label_word2num)\n",
    "dev_data.iloc[:, 1] = dev_data.iloc[:, 1].map(label_word2num)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef build_vocab(text_list):\\n    vocab = {\"<unk>\": 0}  # 添加一个特殊的索引，用于表示未知词\\n\\n    # 遍历所有句子，构建词汇表\\n    for text in text_list:\\n        word_list = jieba.lcut(text)\\n        for word in word_list:\\n            if word not in vocab:\\n                vocab[word] = len(vocab)  # 将每个词映射到唯一的整数索引\\n\\n    return vocab\\n\\nvocabulary = build_vocab(train_data[\\'text\\'].tolist() + dev_data[\\'text\\'].tolist())\\n# 保存词汇表到 JSON 文件, 下次可以直接使用\\nwith open(\\'vocabulary.json\\', \\'w\\', encoding=\\'utf-8\\') as f:\\n    json.dump(vocabulary, f, ensure_ascii=False)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建词汇表\n",
    "import jieba\n",
    "import json\n",
    "'''\n",
    "def build_vocab(text_list):\n",
    "    vocab = {\"<unk>\": 0}  # 添加一个特殊的索引，用于表示未知词\n",
    "\n",
    "    # 遍历所有句子，构建词汇表\n",
    "    for text in text_list:\n",
    "        word_list = jieba.lcut(text)\n",
    "        for word in word_list:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = len(vocab)  # 将每个词映射到唯一的整数索引\n",
    "\n",
    "    return vocab\n",
    "\n",
    "vocabulary = build_vocab(train_data['text'].tolist() + dev_data['text'].tolist())\n",
    "# 保存词汇表到 JSON 文件, 下次可以直接使用\n",
    "with open('vocabulary.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(vocabulary, f, ensure_ascii=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 JSON 文件中的词汇表\n",
    "with open('vocabulary.json', 'r', encoding='utf-8') as f:\n",
    "    vocabulary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转文本向量\n",
    "class TextVector(object):\n",
    "    def __init__(self, text_list, vocabulary):\n",
    "        self.text_list = text_list\n",
    "        self.vocabulary = vocabulary\n",
    "\n",
    "    def text2vector(self, max_len = 30):\n",
    "        all_indexed_sentences = []\n",
    "\n",
    "        # 遍历所有句子，将词汇映射为整数索引，并进行填充\n",
    "        for text in self.text_list:\n",
    "            word_list = jieba.lcut(text)\n",
    "            indexed_sentence = [self.vocabulary.get(word, self.vocabulary[\"<unk>\"]) for word in word_list]\n",
    "\n",
    "            # 填充句子至最大长度\n",
    "            padded_sentence = indexed_sentence + [0] * (max_len - len(indexed_sentence))\n",
    "            all_indexed_sentences.append(padded_sentence)\n",
    "\n",
    "        return all_indexed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_vector = TextVector(train_data['text'].tolist(), vocabulary)\n",
    "train_vectors = train_text_vector.text2vector()\n",
    "dev_text_vector = TextVector(dev_data['text'].tolist(), vocabulary)\n",
    "dev_vectors = dev_text_vector.text2vector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T05:42:28.627563Z",
     "iopub.status.busy": "2022-07-20T05:42:28.626778Z",
     "iopub.status.idle": "2022-07-20T05:42:28.638724Z",
     "shell.execute_reply": "2022-07-20T05:42:28.638000Z",
     "shell.execute_reply.started": "2022-07-20T05:42:28.627517Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Tensor(shape=[30], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [1, 2, 3, 4, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0]), Tensor(shape=[1], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [0]))\n",
      "(Tensor(shape=[30], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [5532, 5416, 2429, 831 , 8997, 475 , 27229, 2101, 276 , 1058, 17183, 1857,\n",
      "        2054, 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   , 0   ,\n",
      "        0   , 0   , 0   , 0   , 0   , 0   ]), Tensor(shape=[1], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
      "       [11]))\n"
     ]
    }
   ],
   "source": [
    "# 定义训练数据集\n",
    "class TrainData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = paddle.to_tensor(train_vectors[index], dtype='int64')\n",
    "        label = paddle.to_tensor(train_data['label'].tolist()[index], dtype='int64')\n",
    "\n",
    "        return text, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(train_vectors)\n",
    "\n",
    "\n",
    "# 定义验证数据集\n",
    "class DevData(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = paddle.to_tensor(dev_vectors[index], dtype='int64')\n",
    "        label = paddle.to_tensor(dev_data['label'].tolist()[index], dtype='int64')\n",
    "\n",
    "        return text, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(dev_vectors)\n",
    "\n",
    "    \n",
    "train_dataset = TrainData()\n",
    "print(train_dataset.__getitem__(0))\n",
    "dev_dataset = DevData()\n",
    "print(dev_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、准备网络模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搭建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义CNN模型：随机嵌入\n",
    "class CNN(nn.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, kernel_size, output_size, maxlength):\n",
    "        super().__init__()\n",
    "        self.embed=nn.Embedding(vocab_size,embedding_dim,padding_idx=0)\n",
    "        self.cnn=nn.Conv1D(embedding_dim, hidden_dim, kernel_size)\n",
    "        self.maxpool=nn.MaxPool1D(maxlength-kernel_size+1)\n",
    "        self.dense=nn.Sequential(nn.Dropout(0.3), nn.Linear(hidden_dim, output_size))\n",
    "    def forward(self,x):\n",
    "        embed_x=self.embed(x)\n",
    "        cnn_x = self.cnn(embed_x.transpose((0, 2, 1)))\n",
    "        pool_x=self.maxpool(cnn_x)\n",
    "        out=self.dense(pool_x.squeeze(-1))\n",
    "        return out\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "vocab_size = len(vocabulary) # 词汇数量\n",
    "embedding_dim = 1024 # 词嵌入维度\n",
    "hidden_dim = 128 # 隐藏层维度，也就是CNN网络层卷积核的个数\n",
    "kernel_size = 3 # 卷积核大小\n",
    "output_size = 14  # 分类的类别数\n",
    "maxlength = 30  # 新闻标题的最大长度\n",
    "\n",
    "model = CNN(vocab_size, embedding_dim, hidden_dim, kernel_size, output_size, maxlength)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (embed): Embedding(251988, 1024, padding_idx=0, sparse=False)\n",
      "  (cnn): Conv1D(1024, 128, kernel_size=[3], data_format=NCL)\n",
      "  (maxpool): MaxPool1D(kernel_size=28, stride=None, padding=0)\n",
      "  (dense): Sequential(\n",
      "    (0): Dropout(p=0.3, axis=None, mode=upscale_in_train)\n",
      "    (1): Linear(in_features=128, out_features=14, dtype=float32)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 输出模型结构\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model_path = './pretrained_models/cnn/final.pdparams'\n",
    "\n",
    "# 加载预训练模型参数\n",
    "model.set_state_dict(paddle.load(pretrain_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "batch_size = 512\n",
    "\n",
    "# 设置GPU环境，如果没有GPU则设置为CPU\n",
    "if paddle.is_compiled_with_cuda() and paddle.get_device() != 'cpu':\n",
    "    paddle.set_device('gpu:0')\n",
    "    print(\"Using GPU.\")\n",
    "else:\n",
    "    paddle.set_device('cpu')\n",
    "    print(\"Using CPU.\")\n",
    "\n",
    "# 定义数据迭代器\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "valid_dataloader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "# 定义优化器\n",
    "opt = paddle.optimizer.Adam(learning_rate=1e-4, parameters=model.parameters(), weight_decay=paddle.regularizer.L2Decay(1e-4))\n",
    "\n",
    "# 定义损失函数\n",
    "loss_fn = paddle.nn.CrossEntropyLoss()\n",
    "\n",
    "# 用于测量准确率的评价指标对象\n",
    "metric =  paddle.metric.Accuracy()\n",
    "\n",
    "# 定义 EarlyStopping 回调函数\n",
    "callback = paddle.callbacks.EarlyStopping(monitor='acc', patience=5, mode='max', verbose=1)\n",
    "# 定义 ModelCheckpoint 回调函数\n",
    "checkpoint_callback = paddle.callbacks.ModelCheckpoint(save_dir='./model/cnn', save_freq=2)\n",
    "# 设置 visualdl 路径\n",
    "log_dir = './visualdl/cnn'\n",
    "visual_callback = paddle.callbacks.VisualDL(log_dir=log_dir)\n",
    "\n",
    "# 使用高层API进行训练\n",
    "model = paddle.Model(model) # 用 Model 封装\n",
    "# 模型配置\n",
    "model.prepare(opt, loss_fn, metric)\n",
    "# 模型训练\n",
    "model.fit(train_dataloader,\n",
    "          valid_dataloader,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          verbose=1,\n",
    "          callbacks= [callback, checkpoint_callback, visual_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、模型测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py:1517: UserWarning: Skip loading for embed.weight. embed.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/root/miniconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py:1517: UserWarning: Skip loading for cnn.weight. cnn.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/root/miniconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py:1517: UserWarning: Skip loading for cnn.bias. cnn.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/root/miniconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py:1517: UserWarning: Skip loading for dense.1.weight. dense.1.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/root/miniconda3/envs/paddle/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py:1517: UserWarning: Skip loading for dense.1.bias. dense.1.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n"
     ]
    }
   ],
   "source": [
    "pre_model = CNN(vocab_size, embedding_dim, hidden_dim, kernel_size, output_size, maxlength)\n",
    "pre_model.set_state_dict(paddle.load('./model/cnn/final.pdparams'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "娱乐\n"
     ]
    }
   ],
   "source": [
    "plain_text_vector = TextVector(['小王子是一本好书'], vocabulary)\n",
    "plain_vector = plain_text_vector.text2vector()\n",
    "plain_tensor = paddle.to_tensor(plain_vector[:30])\n",
    "pre = pre_model(plain_tensor)\n",
    "prob = nn.functional.sigmoid(pre, axis=1)\n",
    "num = paddle.argmax(prob, axis=1).numpy()\n",
    "label = label_num2word[num[0]]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在测试集上预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.883 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "test_text_vector = TextVector(test_data['text'].tolist(), vocabulary)\n",
    "test_vectors = test_text_vector.text2vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for vector in test_vectors:\n",
    "    tensor = paddle.to_tensor(vector[:30])\n",
    "    pre = pre_model(paddle.unsqueeze(tensor, axis=0))\n",
    "    prob = nn.functional.sigmoid(pre, axis=1)\n",
    "    num = paddle.argmax(prob, axis=1).numpy()\n",
    "    label = label_num2word[num[0]]\n",
    "    results.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将list格式的预测结果存储为txt文件，提交格式要求：每行一个类别\n",
    "def write_results(labels, file_path):\n",
    "    with open(file_path, \"w\", encoding=\"utf8\") as f:\n",
    "        f.writelines(\"\\n\".join(labels))\n",
    "\n",
    "write_results(results, \"./result.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因格式要求为zip，故需要将结果文件压缩为submission.zip提交文件\n",
    "!zip 'submission.zip' 'result.txt'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
